# Pattern: Issue-Driven Task Handling

## Overview

This pattern describes the end-to-end workflow for processing GitHub issues as autonomous tasks using @copilot.

## When to Use

Use this pattern when:
- You need to process multiple similar tasks autonomously
- You want a consistent workflow across all AI-generated PRs
- You need audit trails and learning logs
- You're using @copilot for task automation

## Pattern Structure

### Phase 1: Issue Creation
**Who**: Human team member
**How**: Create issue using `.github/ISSUE_TEMPLATE/task.yml`
**Required Fields**:
- Task description (clear, specific)
- Task type (feature, bug, refactor, etc.)
- Success criteria (2-5 observable outcomes)
- Complexity estimate (1-5)
- Priority level

**Example**:
```
Title: [TASK] Add GitHub Actions CI/CD Pipeline

Task Type: DevOps
Complexity: 3 (Moderate)
Priority: High

Success Criteria:
- [ ] Workflow file created at .github/workflows/
- [ ] Runs on Ubuntu latest with Node 18
- [ ] Executes `npm install && npm test`
- [ ] Creates check status on PRs
- [ ] Logs documented in knowledge base
```

### Phase 2: Automatic Processing
**Who**: GitHub Actions + @copilot Agent
**When**: Triggered by `issues.opened` event
**How**:
1. Parse issue template YAML
2. Validate required fields
3. Create feature branch: `copilot/task-{number}`
4. Invoke @copilot agent with task details
5. Receive implementation from @copilot
6. Commit implementation files
7. Create pull request

**Output**: PR with files, tests, docs

### Phase 3: Human Review
**Who**: Team leads, code reviewers
**How**:
1. Review PR generated by @copilot
2. Check implementation against success criteria
3. Request changes if needed
4. Run manual tests if applicable

**Decision Points**:
- **Approve**: Merge to main
- **Request Changes**: @copilot can be asked to revise
- **Close**: If task is no longer relevant

### Phase 4: Knowledge Capture
**Who**: @copilot (automated)
**What Gets Logged**:
- Task ID and title
- Success criteria status (met/not met)
- Time spent
- Files created/modified
- Test results
- Learnings and gotchas

**Where**: `docs/knowledge/insights/` with categorization:
- `execution-log.md` - Chronological record
- `success-log.md` - Successful patterns
- `failure-log.md` - Failed attempts
- `{date}-task-{id}.md` - Detailed task report

## Key Decision Points

### During Issue Creation
```
Is task clear?
  → YES: Proceed
  → NO:  Ask for clarification before submitting
```

### During @copilot Processing
```
Does implementation meet success criteria?
  → YES: Create PR
  → NO:  Log to failure-log.md, post issue comment
```

### During Human Review
```
Is PR ready to merge?
  → YES: Merge and celebrate
  → NO:  Request specific changes with guidance
```

## Common Variations

### A: Simple Task (Complexity 1-2)
- Task: Generate documentation
- Time: < 1 hour
- Review: Quick approval
- Workflow: Create issue → PR → Merge

### B: Feature Task (Complexity 3-4)
- Task: Implement new feature
- Time: 1-4 hours
- Review: Thorough testing
- Workflow: Create issue → PR → Review → Revisions → Merge

### C: Complex Task (Complexity 5)
- Task: Architectural change
- Time: 4+ hours (may need chunking)
- Review: Team discussion + approval
- Workflow: Create issue → PR → Discussion → ADR → Merge

## Workflow Diagram

```
┌─────────────────┐
│ Human Creates   │
│ Issue via       │
│ Template        │
└────────┬────────┘
         │
         ▼
┌─────────────────────────┐
│ GitHub Actions Trigger  │
│ - Parse template YAML   │
│ - Validate fields       │
│ - Create branch         │
└────────┬────────────────┘
         │
         ▼
┌──────────────────────┐
│ @copilot Agent       │
│ - Process task       │
│ - Generate code      │
│ - Run tests          │
└────────┬─────────────┘
         │
         ▼
┌──────────────────────┐
│ Commit & Create PR   │
│ - Push to branch     │
│ - Create pull req    │
└────────┬─────────────┘
         │
         ▼
┌──────────────────────┐
│ Human Reviews PR     │
│ - Check code         │
│ - Verify tests       │
└────────┬─────────────┘
         │
    ┌────┴─────┐
    │           │
    ▼           ▼
┌──────┐    ┌────────┐
│Merge │    │ Revise │
│ PR   │    │ Again  │
└──┬───┘    └──┬─────┘
   │           │
   └─────┬─────┘
         │
         ▼
┌──────────────────────┐
│ Knowledge Capture    │
│ - Log to insights/   │
│ - Update patterns    │
│ - Close issue        │
└──────────────────────┘
```

## Checklist: Before Creating Issue

- [ ] Task description is clear and specific
- [ ] Success criteria are measurable (not subjective)
- [ ] Task type is chosen (feature, bug, etc.)
- [ ] Complexity is realistic (1-5 scale)
- [ ] Priority is set (critical, high, medium, low)
- [ ] Any reference links are included
- [ ] Prerequisite issues are resolved
- [ ] You've read relevant patterns in `docs/knowledge/patterns/`

## Checklist: During Code Review

- [ ] All files have correct syntax (YAML, JSON, Bash, etc.)
- [ ] Success criteria are met
- [ ] Code follows project style
- [ ] Tests pass (where applicable)
- [ ] Documentation is updated
- [ ] Knowledge base entry is created

## Checklist: After Merge

- [ ] Close the original issue
- [ ] Thank @copilot if helpful
- [ ] Review and categorize the learning log
- [ ] Update relevant patterns if new insights
- [ ] Consider if this pattern is reusable

## Common Pitfalls

### ❌ Pitfall 1: Vague Success Criteria
```
Bad:  "Make the code better"
Good: "Reduce function complexity to < 10 cyclomatic complexity"
```

### ❌ Pitfall 2: Task Too Large
```
Bad:  "Rewrite entire authentication system"
Good: "Add OAuth2 support with tests and docs"
       (Split rewrite into 3-5 smaller tasks)
```

### ❌ Pitfall 3: Missing Context
```
Bad:  "Fix the bug" (no details)
Good: "Fix bug where login fails on mobile (see #456, Safari only)"
```

### ❌ Pitfall 4: Ignoring Feedback
```
Bad:  Creating issue, ignoring PR feedback
Good: Use feedback to improve issue clarity for future tasks
```

## Tips for Success

### Tip 1: Learn from History
Before creating a task, check `docs/knowledge/insights/`:
- Has a similar task been done before?
- What patterns were used?
- What challenges came up?

### Tip 2: Write Clear Acceptance Criteria
```
Success Criteria:
- [ ] All unit tests pass
- [ ] Code coverage ≥ 80%
- [ ] No new console warnings
- [ ] README updated with examples
- [ ] Performance tests show no regression
```

### Tip 3: Reference Related Tasks
```
Acceptance Notes:
- Related to issue #234 (API design)
- Builds on pattern in docs/knowledge/patterns/testing.md
- Follow style guide in CONTRIBUTING.md
```

### Tip 4: Post-Merge Review
After merging a PR:
- Read the knowledge log entry
- Identify what went well
- Identify what could improve
- Document patterns that should be reused

## Metrics to Track

- **Cycle Time**: Issue creation → PR merged
- **Quality Score**: Tests passing, code review feedback
- **Learning Velocity**: New patterns documented per week
- **Reuse Rate**: % of tasks using existing patterns
- **Agent Consistency**: Success rate across different AI models

## Related Patterns

- [GitHub Actions Pattern](./github-actions-pattern.md) - Workflow automation
- [Knowledge Capture Pattern](./knowledge-capture.md) - Documentation
- [PR Review Pattern](./pr-review.md) - Code review best practices

## Evolution of This Pattern

As you use this pattern, it will evolve:

**Week 1**: Basic issue → PR workflow
**Week 2**: Refined success criteria format
**Week 3**: Added complexity estimates
**Month 1**: Full knowledge base integration
**Month 3**: Metrics-driven improvements

Document changes in `docs/knowledge/patterns/issue-handling-evolution.md`

---

**Pattern Owner**: @copilot
**Last Updated**: 2026-01-06
**Usage Count**: [Auto-tracked]
**Success Rate**: [Auto-calculated]
