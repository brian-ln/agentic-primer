# Issue-to-PR Workflow Pattern

## Problem

How can @copilot autonomously transform a GitHub issue into a complete pull request with proper tracking, testing, and review assignment?

## Context

This pattern applies when:

- An issue is labeled with `copilot` or `ai-task`
- The issue contains structured task description and acceptance criteria
- Automated PR creation and review assignment are desired

## Solution

### Workflow Stages

```
Issue Created
     |
     v
[1. Trigger Detection]
     |-- Check for copilot label
     |-- Validate issue structure
     v
[2. Environment Setup]
     |-- Checkout repository
     |-- Create feature branch: copilot/issue-{number}
     v
[3. Task Parsing]
     |-- Extract task description
     |-- Parse acceptance criteria
     |-- Identify context and constraints
     v
[4. Implementation]
     |-- Read relevant knowledge base entries
     |-- Generate code changes
     |-- Add tests per acceptance criteria
     v
[5. Validation]
     |-- Run linting
     |-- Execute tests
     |-- Check coverage
     v
[6. PR Creation]
     |-- Commit changes
     |-- Create PR with structured body
     |-- Link to issue with "Fixes #N"
     v
[7. Review Assignment]
     |-- CODEOWNERS triggers auto-assignment
     |-- @copilot posts review comment
     v
[8. Logging]
     |-- Write execution log
     +-- Update issue with status
```

### Branch Naming Convention

```
copilot/issue-{number}-{slug}
```

Examples:
- `copilot/issue-42-greeting-function`
- `copilot/issue-99-fix-auth-bug`

### PR Body Template

```markdown
## Summary
Automated implementation for issue #{number}.

Fixes #{number}

## Changes
- {list of changes}

## Acceptance Criteria
- [ ] {criterion 1}
- [ ] {criterion 2}

## Test Coverage
- Tests added: {count}
- Coverage: {percent}%

---
*Generated by @copilot via issue-driven automation*
```

### Execution Logging

Each execution creates a JSON log:

```json
{
  "execution_id": "exec-YYYYMMDD-HHMMSS-{issue_number}",
  "issue_number": 42,
  "issue_title": "Task title",
  "start_time": "ISO8601",
  "end_time": "ISO8601",
  "duration_seconds": 37,
  "status": "success|failure",
  "agent": "opus|sonnet|haiku|copilot",
  "branch": "copilot/issue-42-slug",
  "pr_number": 43,
  "files_created": ["path/to/file.ts"],
  "tests_passed": true,
  "coverage_percent": 80,
  "errors": []
}
```

## Example

### Input: Issue #42

```yaml
Title: "[Copilot Task] Add greeting function"
Labels: ["copilot", "ai-task"]
Body: |
  ## Task Description
  Create a greeting function that returns "Hello, {name}!"

  ## Acceptance Criteria
  - [ ] Function greet(name) exists
  - [ ] Returns formatted string
  - [ ] Unit tests included
```

### Output: PR #43

```yaml
Title: "feat: Add greeting function"
Branch: copilot/issue-42-greeting
Files:
  - src/greeting.ts
  - src/greeting.test.ts
Body: |
  Fixes #42

  Added greet() function with full test coverage.
```

## Variations

### Minimal Issue (No Template)

When an issue lacks structured format:
1. Parse title for intent
2. Use entire body as context
3. Generate reasonable acceptance criteria
4. Note assumptions in PR description

### Multi-File Changes

When implementation spans many files:
1. Group related changes into logical commits
2. Use atomic commits for rollback safety
3. Document file relationships in PR

### Test-First Approach

Optionally invert the flow:
1. Generate tests from acceptance criteria first
2. Implement until tests pass
3. Refactor and document

## Related

- **Decision:** [001-copilot-automation](../decisions/001-copilot-automation.md)
- **Insight:** [multi-agent-compatibility](../insights/multi-agent-compatibility.md)

## Metadata

- **Created:** 2026-01-06
- **Author:** @copilot
- **Related Issues:** Initial system design
